# Copyright: (c) OpenChiip Organization. https://github.com/OpenChiip/Chiip
# Copyright: (c) <aigc@openchiip.com>
# Generated By Model: Qwen2.5-coder
# Released under the AIGCGPL-1.0 License. For more information, see [https://github.com/OpenChiip/AIGCGPL/blob/main/LICENSE].
# This code was generated using a generative artificial intelligence system and is licensed under the Artificial Intelligence Generated Code General Public License (AIGCGPL). 

"""
AI接口模块，负责与AI模型的交互
"""
import json
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, Any, List, Optional, Union

import openai
from config import Config
from prompts import get_system_prompt

logger = logging.getLogger(__name__)

@dataclass
class Message:
    """对话消息"""
    role: str              # 消息角色：system/user/assistant
    content: str           # 消息内容
    name: Optional[str] = None  # 可选的消息发送者名称

@dataclass
class ModelResponse:
    """模型响应"""
    content: str           # 响应内容
    finish_reason: str     # 结束原因
    raw_response: Dict[str, Any]  # 原始响应数据

class AIModelInterface(ABC):
    """AI模型接口基类"""
    
    def __init__(self, config: Config):
        """
        初始化AI模型接口
        
        Args:
            config: 配置管理器实例
        """
        self.config = config
        self.conversation_history: List[Message] = []
        self.system_prompt = get_system_prompt()
        
        # 添加系统提示到对话历史
        self.conversation_history.append(Message(
            role="system",
            content=self.system_prompt
        ))
    
    @abstractmethod
    async def generate_response(self, prompt: str) -> ModelResponse:
        """
        生成响应
        
        Args:
            prompt: 用户输入的提示词
            
        Returns:
            ModelResponse: 模型响应
        """
        pass
    
    def add_message(self, role: str, content: str, name: Optional[str] = None) -> None:
        """
        添加消息到对话历史
        
        Args:
            role: 消息角色
            content: 消息内容
            name: 消息发送者名称（可选）
        """
        self.conversation_history.append(Message(
            role=role,
            content=content,
            name=name
        ))
    
    def clear_history(self) -> None:
        """清除对话历史，但保留系统提示"""
        self.conversation_history = [self.conversation_history[0]]
    
    def get_conversation_context(self) -> List[Dict[str, str]]:
        """
        获取对话上下文
        
        Returns:
            List[Dict[str, str]]: 对话消息列表
        """
        return [
            {
                'role': msg.role,
                'content': msg.content,
                **(({'name': msg.name} if msg.name else {}))
            }
            for msg in self.conversation_history
        ]

class LocalAIModel(AIModelInterface):
    """本地AI模型实现"""
    
    async def generate_response(self, prompt: str) -> ModelResponse:
        """
        使用本地模型生成响应
        
        Args:
            prompt: 用户输入的提示词
            
        Returns:
            ModelResponse: 模型响应
        """
        try:
            # 添加用户消息到对话历史
            self.add_message("user", prompt)
            
            # TODO: 实现本地模型调用
            # 当前返回模拟响应
            response_content = "这是本地模型的模拟响应"
            
            # 添加助手消息到对话历史
            self.add_message("assistant", response_content)
            
            return ModelResponse(
                content=response_content,
                finish_reason="stop",
                raw_response={
                    'content': response_content,
                    'finish_reason': 'stop'
                }
            )
            
        except Exception as e:
            logger.error(f"本地模型生成响应时出错: {e}", exc_info=True)
            raise

class APIAIModel(AIModelInterface):
    """API型AI模型实现"""
    
    def __init__(self, config: Config):
        """
        初始化API型AI模型
        
        Args:
            config: 配置管理器实例
        """
        super().__init__(config)
        self.client = openai.AsyncOpenAI(
            api_key=config.get('model.api_key'),
            base_url=config.get('model.api_endpoint'),
            max_retries=config.get('model.max_retries', 2)
        )
        self.model_name = config.get('model.name')
        self.temperature = config.get('model.temperature', 0.7)
        self.max_tokens = config.get('model.max_tokens', 4000)
        self.timeout = config.get('model.timeout', 300.0)
    
    async def generate_response(self, prompt: str) -> ModelResponse:
        """
        通过API生成响应
        
        Args:
            prompt: 用户输入的提示词
            
        Returns:
            ModelResponse: 模型响应
        """
        try:
            # 添加用户消息到对话历史
            self.add_message("user", prompt)
            
            # 构建API请求
            response = await self.client.chat.completions.create(
                model=self.model_name,
                messages=self.get_conversation_context(),
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                timeout=self.timeout
            )
            
            # 处理响应
            content = response.choices[0].message.content
            self.add_message("assistant", content)
            
            return ModelResponse(
                content=content,
                finish_reason=response.choices[0].finish_reason,
                raw_response={
                    'content': content,
                    'usage': {
                        'prompt_tokens': response.usage.prompt_tokens,
                        'completion_tokens': response.usage.completion_tokens
                    },
                    'raw_response': response
                }
            )
            
        except openai.APIConnectionError as e:
            logger.error(f"API连接错误: {e}")
            raise
        except openai.RateLimitError as e:
            logger.error(f"API限速: {e}")
            raise
        except openai.APIError as e:
            logger.error(f"API请求错误: {e}")
            raise
        except Exception as e:
            logger.error(f"未知错误: {e}", exc_info=True)
            raise

class AIModelFactory:
    """AI模型工厂类"""
    
    @staticmethod
    def create_model(config: Config) -> AIModelInterface:
        """
        创建AI模型实例
        
        Args:
            config: 配置管理器实例
            
        Returns:
            AIModelInterface: AI模型实例
        """
        model_type = config.get('model.type', 'local')
        
        if model_type == 'local':
            return LocalAIModel(config)
        elif model_type == 'api':
            return APIAIModel(config)
        else:
            raise ValueError(f"不支持的模型类型: {model_type}")

class ResponseParser:
    """响应解析器"""
    
    @staticmethod
    def parse_code_blocks(response: str) -> List[Dict[str, str]]:
        """
        从响应中解析代码块
        
        Args:
            response: 模型响应内容
            
        Returns:
            List[Dict[str, str]]: 代码块列表，每个代码块包含：
                - language: 编程语言
                - code: 代码内容
        """
        from utils.text_processing import extract_code_blocks
        return extract_code_blocks(response)
    
    @staticmethod
    def parse_file_operations(response: str) -> List[Dict[str, Any]]:
        """
        从响应中解析文件操作指令
        
        Args:
            response: 模型响应内容
            
        Returns:
            List[Dict[str, Any]]: 文件操作列表，每个操作包含：
                - operation: 操作类型（create/modify/delete）
                - path: 文件路径
                - content: 文件内容（对于create和modify操作）
        """
        import re
        operations = []
        
        # 定义文件操作的正则表达式模式
        patterns = {
            'create': r'(?:创建文件|create file)[：:]\s*([^\n]+)\n```(?:\w+)?\n(.*?)```',
            'modify': r'(?:修改文件|modify file)[：:]\s*([^\n]+)\n```(?:\w+)?\n(.*?)```',
            'delete': r'(?:删除文件|delete file)[：:]\s*([^\n]+)'
        }
        
        # 查找创建和修改文件的指令
        for op_type in ['create', 'modify']:
            matches = re.finditer(patterns[op_type], response, re.DOTALL)
            for match in matches:
                path = match.group(1).strip()
                content = match.group(2).strip()
                operations.append({
                    'operation': op_type,
                    'path': path,
                    'content': content
                })
        
        # 查找删除文件的指令
        delete_matches = re.finditer(patterns['delete'], response)
        for match in delete_matches:
            path = match.group(1).strip()
            operations.append({
                'operation': 'delete',
                'path': path
            })
        
        # 解析XML格式的文件操作
        xml_patterns = {
            'create': r'<create_file>\s*<path>(.*?)</path>\s*<content>(.*?)</content>\s*</create_file>',
            'modify': r'<modify_file>\s*<path>(.*?)</path>\s*<content>(.*?)</content>\s*</modify_file>',
            'delete': r'<delete_file>\s*<path>(.*?)</path>\s*</delete_file>'
        }
        
        # 查找XML格式的创建和修改文件指令
        for op_type in ['create', 'modify']:
            matches = re.finditer(xml_patterns[op_type], response, re.DOTALL)
            for match in matches:
                path = match.group(1).strip()
                content = match.group(2).strip()
                operations.append({
                    'operation': op_type,
                    'path': path,
                    'content': content
                })
        
        # 查找XML格式的删除文件指令
        delete_matches = re.finditer(xml_patterns['delete'], response)
        for match in delete_matches:
            path = match.group(1).strip()
            operations.append({
                'operation': 'delete',
                'path': path
            })
        
        return operations
    
    @staticmethod
    def parse_requirements(response: str) -> List[str]:
        """
        从响应中解析依赖需求
        
        Args:
            response: 模型响应内容
            
        Returns:
            List[str]: 依赖包列表
        """
        from utils.text_processing import extract_requirements
        return extract_requirements(response)

class AIAssistant:
    """AI助手类，提供高级接口"""
    
    def __init__(self, config: Config):
        """
        初始化AI助手
        
        Args:
            config: 配置管理器实例
        """
        self.config = config
        self.model = AIModelFactory.create_model(config)
        self.parser = ResponseParser()
    
    async def process_request(self, request: str) -> Dict[str, Any]:
        """
        处理用户请求
        
        Args:
            request: 用户请求内容
            
        Returns:
            Dict[str, Any]: 处理结果，包含：
                - response: 原始响应内容
                - code_blocks: 代码块列表
                - file_operations: 文件操作列表
                - requirements: 依赖需求列表
        """
        try:
            # 生成响应
            response = await self.model.generate_response(request)
            
            # 解析响应
            code_blocks = self.parser.parse_code_blocks(response.content)
            file_operations = self.parser.parse_file_operations(response.content)
            requirements = self.parser.parse_requirements(response.content)
            
            return {
                'response': response.content,
                'code_blocks': code_blocks,
                'file_operations': file_operations,
                'requirements': requirements
            }
            
        except Exception as e:
            logger.error(f"处理请求时出错: {e}", exc_info=True)
            raise
    
    def clear_conversation(self) -> None:
        """清除对话历史"""
        self.model.clear_history()